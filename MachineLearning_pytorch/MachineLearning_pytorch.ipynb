{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference: https://zhuanlan.zhihu.com/p/101799677"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0469e-38, 9.3674e-39, 9.9184e-39],\n",
      "        [8.7245e-39, 9.2755e-39, 8.9082e-39],\n",
      "        [9.9184e-39, 8.4490e-39, 9.6429e-39],\n",
      "        [1.0653e-38, 1.0469e-38, 4.2246e-39],\n",
      "        [1.0378e-38, 9.6429e-39, 9.2755e-39]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3568, 0.1898, 0.9638],\n",
      "        [0.8893, 0.9131, 0.9649],\n",
      "        [0.1871, 0.2894, 0.4746],\n",
      "        [0.3597, 0.4167, 0.0734],\n",
      "        [0.6067, 0.8453, 0.1729]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = x.new_ones(5, 3, dtype=torch.double)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6485,  0.3901, -1.5344],\n",
      "        [-0.1758, -2.4787, -0.0823],\n",
      "        [ 1.1017,  0.2345, -0.4665],\n",
      "        [ 1.0825, -1.8110,  0.7313],\n",
      "        [ 1.1274,  1.0616,  0.7046]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn_like(x, dtype=torch.float)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 獲取size\n",
    "print(x.size())\n",
    "torch.Size([5,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5735,  1.1917, -0.7651],\n",
      "        [ 0.8087, -2.3707,  0.0809],\n",
      "        [ 1.3146,  0.5293,  0.3896],\n",
      "        [ 1.6812, -1.2449,  1.6115],\n",
      "        [ 1.3525,  1.2751,  1.6569]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5,3)\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5735,  1.1917, -0.7651],\n",
      "        [ 0.8087, -2.3707,  0.0809],\n",
      "        [ 1.3146,  0.5293,  0.3896],\n",
      "        [ 1.6812, -1.2449,  1.6115],\n",
      "        [ 1.3525,  1.2751,  1.6569]])\n"
     ]
    }
   ],
   "source": [
    "# 加法2\n",
    "print(torch.add(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5735,  1.1917, -0.7651],\n",
      "        [ 0.8087, -2.3707,  0.0809],\n",
      "        [ 1.3146,  0.5293,  0.3896],\n",
      "        [ 1.6812, -1.2449,  1.6115],\n",
      "        [ 1.3525,  1.2751,  1.6569]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5,3)\n",
    "torch.add(x, y, out = result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5735,  1.1917, -0.7651],\n",
      "        [ 0.8087, -2.3707,  0.0809],\n",
      "        [ 1.3146,  0.5293,  0.3896],\n",
      "        [ 1.6812, -1.2449,  1.6115],\n",
      "        [ 1.3525,  1.2751,  1.6569]])\n"
     ]
    }
   ],
   "source": [
    "# 替換, adds x to y\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3901, -2.4787,  0.2345, -1.8110,  1.0616])\n"
     ]
    }
   ],
   "source": [
    "print(x[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "# torch.view与Numpy的reshape类似\n",
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8) # size -1 從其他維度推斷\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.7742])\n",
      "1.7742080688476562\n"
     ]
    }
   ],
   "source": [
    "# 如果你有只有一个元素的张量，使用.item()来得到Python数据类型的数值\n",
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将Torch Tensor转换成NumPy array，反之亦然，这是轻而易举的。 Torch Tensor和NumPy array将共享它们的底层内存位置，更改其中一个将更改另一个。 将Torch Tensor转换为NumPy array。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# see how the numpy array changed in value\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy Array 转化成 Torch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 使用from_numpy自動轉化\n",
    "import numpy as np\n",
    "a = np.ones(7)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有的 Tensor 类型默认都是基于CPU， CharTensor 类型不支持到 NumPy 的转换."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.7742], device='cuda:0')\n",
      "tensor([2.7742], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# CUDA 张量. 使用.to 方法 可以将Tensor移动到任何设备中\n",
    "\n",
    "# is_available 函數判斷是否有cuda可以使用\n",
    "# ``torch.device`` 將張量移動到指定的設備中\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") # a CUDA 設備對象\n",
    "    y = torch.ones_like(x, device=device) # 直接從GPU創建張量 \n",
    "    x = x.to(device) #或者直接使用``.to(\"cuda\")``將張量移動到CUDA中\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to('cpu', torch.double))  # ``.TO``也會對變量的類型做更改"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自动求导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x000001656E957EC8>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "None\n",
      "True\n",
      "<SumBackward0 object at 0x000001656E9F3808>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 2)\n",
    "a = ((a*3)/(a-1))\n",
    "print(a.requires_grad)\n",
    "print(a.grad_fn)\n",
    "\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "b = (a*a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1390.2953, -179.9784,  978.3918], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "    \n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"
     ]
    }
   ],
   "source": [
    "gradients = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
    "y.backward(gradients)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "print((x**2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x**2).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-58-8be51be2434d>, line 39)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-58-8be51be2434d>\"\u001b[1;36m, line \u001b[1;32m39\u001b[0m\n\u001b[1;33m    (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "Net(\n",
    "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
    "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
    "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
    "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
    "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用cifar10训练一个分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, \n",
    "                                        download=True, transform= transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, \n",
    "                                          shuffle=True, num_workers=2)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                          download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                            shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 展示圖像的函數\n",
    "def imshow(img):\n",
    "    img = img/2 + 0.5  #unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    \n",
    "# 獲取隨機數據\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# 展示圖象\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# 顯示圖像標簽\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))\n",
    "# Predicted:  plane plane plane plane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "refernce: https://www.jiqizhixin.com/articles/2018-04-11-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch 是一个建立在 Torch 库之上的 Python 包，旨在加速深度学习应用。\n",
    "\n",
    "PyTorch 提供一种类似 NumPy 的抽象方法来表征张量（或多维数组），它可以利用 GPU 来加速训练。\n",
    "\n",
    "**1.1 PyTorch 张量**\n",
    "\n",
    "PyTorch 的关键数据结构是张量，即多维数组。其功能与 NumPy 的 ndarray 对象类似，如下我们可以使用 torch.Tensor() 创建张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type:  <class 'torch.Tensor'>  and size:  torch.Size([10, 20])\n"
     ]
    }
   ],
   "source": [
    "# Generate a 2-D pytorch tensor (i.e., a matrix)\n",
    "import torch\n",
    "pytorch_tensor = torch.Tensor(10, 20)\n",
    "print(\"type: \", type(pytorch_tensor), \" and size: \", pytorch_tensor.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你需要一个兼容 NumPy 的表征，或者你想从现有的 NumPy 对象中创建一个 PyTorch 张量，那么就很简单了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'numpy.ndarray'>  and size (10, 20)\n"
     ]
    }
   ],
   "source": [
    "# Convert the pytorch tensor to a numpy array:\n",
    "numpy_tensor = pytorch_tensor.numpy()\n",
    "print(\"type:\", type(numpy_tensor), \" and size\", numpy_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'numpy.ndarray'>  and size torch.Size([10, 20])\n"
     ]
    }
   ],
   "source": [
    "# Convert the numpy array to a Pytorch Tensor:\n",
    "print(\"type:\", type(numpy_tensor), \" and size\", torch.Tensor(numpy_tensor).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 PyTorch vs. NumPy\n",
    "\n",
    "PyTorch 并不是 NumPy 的简单替代品，但它实现了很多 NumPy 功能。其中有一个不便之处是其命名规则，有时候它和 NumPy 的命名方法相当不同。我们来举几个例子说明其中的区别："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 張量創建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "t = torch.rand(2,4,3,5)\n",
    "a = np.random.rand(2,4,3,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 張量分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor[0, 1:3, :, 4]:\n",
      " tensor([[0.5657, 0.0191, 0.9172],\n",
      "        [0.6028, 0.5617, 0.6247]])\n",
      "NdArray[0, 1:3, :, 4]:\n",
      "] [[0.56572026 0.0191229  0.91722834]\n",
      " [0.60282016 0.56172985 0.6247015 ]]\n"
     ]
    }
   ],
   "source": [
    "t = torch.rand(2,4,3,5)\n",
    "a = t.numpy()\n",
    "pytorch_slice = t[0, 1:3, :, 4]\n",
    "numpy_slice = a[0, 1:3, :, 4]\n",
    "print('Tensor[0, 1:3, :, 4]:\\n', pytorch_slice)\n",
    "print('NdArray[0, 1:3, :, 4]:\\n]', numpy_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 張量 Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t - 0.5\n",
    "a = t.numpy()\n",
    "pytorch_masked = t[t > 0]\n",
    "numpy_masked = a[a > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2457, 0.4548, 0.3916, 0.1211, 0.3645, 0.3988, 0.4931, 0.0657, 0.0909,\n",
       "        0.3600, 0.0739, 0.2596, 0.1497, 0.0062, 0.4172, 0.4633, 0.4846, 0.1277,\n",
       "        0.1895, 0.1028, 0.2819, 0.2775, 0.0617, 0.3617, 0.1710, 0.1247, 0.4955,\n",
       "        0.4008, 0.0846, 0.1874, 0.0955, 0.1589, 0.2208, 0.0342, 0.1286, 0.1682,\n",
       "        0.4501, 0.3861, 0.0430, 0.2585, 0.0258, 0.4081, 0.3300, 0.0176, 0.3368,\n",
       "        0.4909, 0.3911, 0.1987, 0.0204, 0.1998, 0.2009, 0.2475, 0.4139, 0.4928,\n",
       "        0.0423, 0.2908, 0.1607, 0.0605, 0.4951, 0.4088, 0.4776, 0.0786, 0.1063,\n",
       "        0.4471, 0.1251, 0.1979])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24573803, 0.45478058, 0.39158708, 0.12105626, 0.36446506,\n",
       "       0.39877683, 0.49306166, 0.06572026, 0.09094918, 0.35999125,\n",
       "       0.07388479, 0.25956297, 0.14970964, 0.00621635, 0.41722834,\n",
       "       0.46329546, 0.48456812, 0.12774795, 0.18951124, 0.10282016,\n",
       "       0.28188038, 0.27752513, 0.06172985, 0.36165935, 0.17103124,\n",
       "       0.1247015 , 0.49548292, 0.40083027, 0.08458453, 0.18740821,\n",
       "       0.09546596, 0.1588915 , 0.22083509, 0.0342406 , 0.12859708,\n",
       "       0.1681754 , 0.45011836, 0.38609642, 0.04301894, 0.2585023 ,\n",
       "       0.02581698, 0.4081207 , 0.32999963, 0.01759183, 0.33684522,\n",
       "       0.49088925, 0.39105463, 0.19867045, 0.02043313, 0.1998182 ,\n",
       "       0.20092309, 0.2475245 , 0.41385168, 0.4927625 , 0.04231614,\n",
       "       0.2908342 , 0.16065854, 0.06054449, 0.49507236, 0.4088238 ,\n",
       "       0.47757286, 0.07863462, 0.10628468, 0.44710445, 0.12513036,\n",
       "       0.19788736], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_masked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 張量重塑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_reshape = t.view([6, 5, 4])\n",
    "numpy_reshape = a.reshape([6, 5, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3913,  0.2457,  0.4548, -0.4512],\n",
       "         [ 0.3916, -0.1376,  0.1211,  0.3645],\n",
       "         [ 0.3988,  0.4931, -0.0152, -0.0439],\n",
       "         [-0.3834, -0.3368, -0.2734, -0.3964],\n",
       "         [-0.0042, -0.0655, -0.0392,  0.0657]],\n",
       "\n",
       "        [[ 0.0909,  0.3600,  0.0739, -0.2824],\n",
       "         [-0.4809,  0.2596,  0.1497,  0.0062],\n",
       "         [-0.1552,  0.4172,  0.4633,  0.4846],\n",
       "         [ 0.1277,  0.1895,  0.1028, -0.1224],\n",
       "         [ 0.2819, -0.1942,  0.2775,  0.0617]],\n",
       "\n",
       "        [[-0.1235, -0.1324,  0.3617,  0.1710],\n",
       "         [ 0.1247,  0.4955, -0.2146, -0.4121],\n",
       "         [ 0.4008, -0.3624, -0.1591, -0.3291],\n",
       "         [-0.0110,  0.0846,  0.1874, -0.4616],\n",
       "         [-0.4480, -0.1253,  0.0955,  0.1589]],\n",
       "\n",
       "        [[ 0.2208, -0.0857, -0.2192,  0.0342],\n",
       "         [ 0.1286, -0.0972,  0.1682, -0.3382],\n",
       "         [-0.1203,  0.4501,  0.3861,  0.0430],\n",
       "         [-0.3361, -0.1192, -0.0364, -0.3737],\n",
       "         [-0.3252,  0.2585,  0.0258, -0.0049]],\n",
       "\n",
       "        [[ 0.4081, -0.4556, -0.1712, -0.4452],\n",
       "         [-0.3816,  0.3300, -0.2546, -0.3331],\n",
       "         [ 0.0176,  0.3368,  0.4909, -0.4230],\n",
       "         [ 0.3911,  0.1987, -0.4602,  0.0204],\n",
       "         [ 0.1998, -0.0035,  0.2009, -0.3875]],\n",
       "\n",
       "        [[-0.2464,  0.2475,  0.4139,  0.4928],\n",
       "         [ 0.0423, -0.2289,  0.2908,  0.1607],\n",
       "         [-0.1268,  0.0605,  0.4951, -0.3449],\n",
       "         [ 0.4088,  0.4776, -0.0609,  0.0786],\n",
       "         [ 0.1063,  0.4471,  0.1251,  0.1979]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_reshape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.3912791 ,  0.24573803,  0.45478058, -0.45120567],\n",
       "        [ 0.39158708, -0.13757849,  0.12105626,  0.36446506],\n",
       "        [ 0.39877683,  0.49306166, -0.01521182, -0.04394877],\n",
       "        [-0.38341808, -0.33683634, -0.27335304, -0.3963651 ],\n",
       "        [-0.00416881, -0.06545174, -0.03920037,  0.06572026]],\n",
       "\n",
       "       [[ 0.09094918,  0.35999125,  0.07388479, -0.28238183],\n",
       "        [-0.4808771 ,  0.25956297,  0.14970964,  0.00621635],\n",
       "        [-0.15522039,  0.41722834,  0.46329546,  0.48456812],\n",
       "        [ 0.12774795,  0.18951124,  0.10282016, -0.12238079],\n",
       "        [ 0.28188038, -0.19418973,  0.27752513,  0.06172985]],\n",
       "\n",
       "       [[-0.12351465, -0.13244814,  0.36165935,  0.17103124],\n",
       "        [ 0.1247015 ,  0.49548292, -0.2146399 , -0.41214764],\n",
       "        [ 0.40083027, -0.36242276, -0.1590749 , -0.32912892],\n",
       "        [-0.01102668,  0.08458453,  0.18740821, -0.46156746],\n",
       "        [-0.44796753, -0.1252867 ,  0.09546596,  0.1588915 ]],\n",
       "\n",
       "       [[ 0.22083509, -0.08572704, -0.21920216,  0.0342406 ],\n",
       "        [ 0.12859708, -0.0972212 ,  0.1681754 , -0.33815652],\n",
       "        [-0.12030417,  0.45011836,  0.38609642,  0.04301894],\n",
       "        [-0.33611935, -0.11923742, -0.03642416, -0.37368816],\n",
       "        [-0.32521623,  0.2585023 ,  0.02581698, -0.00486749]],\n",
       "\n",
       "       [[ 0.4081207 , -0.45556676, -0.17122573, -0.4452237 ],\n",
       "        [-0.3816144 ,  0.32999963, -0.25463766, -0.33307117],\n",
       "        [ 0.01759183,  0.33684522,  0.49088925, -0.42296076],\n",
       "        [ 0.39105463,  0.19867045, -0.46018028,  0.02043313],\n",
       "        [ 0.1998182 , -0.00353593,  0.20092309, -0.38752174]],\n",
       "\n",
       "       [[-0.2463631 ,  0.2475245 ,  0.41385168,  0.4927625 ],\n",
       "        [ 0.04231614, -0.22885269,  0.2908342 ,  0.16065854],\n",
       "        [-0.1267854 ,  0.06054449,  0.49507236, -0.3449272 ],\n",
       "        [ 0.4088238 ,  0.47757286, -0.06085688,  0.07863462],\n",
       "        [ 0.10628468,  0.44710445,  0.12513036,  0.19788736]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_reshape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Pytorch變量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch張量的簡單封裝<br>\n",
    "幫組建立計算圖<br>\n",
    "AUTOGRAD(自動微分庫)的必要部分<br>\n",
    "將關於這些變量的梯度保存在.grad中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/pytorch001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算图和变量：在 PyTorch 中，神经网络会使用相互连接的变量作为计算图来表示。PyTorch 允许通过代码构建计算图来构建网络模型；之后 PyTorch 会简化估计模型权重的流程，例如通过自动计算梯度的方式。\n",
    "\n",
    "举例来说，假设我们想构建两层模型，那么首先要为输入和输出创建张量变量。我们可以将 PyTorch Tensor 包装进 Variable 对象中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "x = Variable(torch.randn(4, 1), requires_grad=False)\n",
    "y = Variable(torch.randn(3, 1), requires_grad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们把 requires_grad 设置为 True，表明我们想要自动计算梯度，这将用于反向传播中以优化权重。\n",
    "\n",
    "现在我们来定义权重："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = Variable(torch.randn(5, 4), requires_grad=True)\n",
    "w2 = Variable(torch.randn(3, 5), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3505, -0.8565, -0.2792,  0.9894],\n",
      "        [ 0.8291, -1.7060,  0.1151, -0.7268],\n",
      "        [-0.1877, -1.1323, -1.0742, -1.2432],\n",
      "        [-1.5642, -1.0690, -0.1425,  1.4996],\n",
      "        [-0.1871,  0.7426, -1.4178,  0.7577]], requires_grad=True) \n",
      "\n",
      "torch.Size([5, 4]) \n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 訓練模型\n",
    "def model_forward(x):\n",
    "    return F.sigmoid(w2@F.sigmoid(w1@x))\n",
    "\n",
    "print(w1, '\\n')\n",
    "print(w1.data.shape,'\\n')\n",
    "print(w1.grad)  # Ubutuakktm non-existent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 PyTorch 反向传播\n",
    "\n",
    "这样我们有了输入和目标、模型权重，那么是时候训练模型了。我们需要三个组件：\n",
    "\n",
    "损失函数：描述我们模型的预测距离目标还有多远；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "优化算法：用于更新权重；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.SGD([w1, w2], lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "反向传播步骤："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Norto\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    loss = criterion(model_forward(x), y)\n",
    "    optimizer.zero_grad() # Zero-out previous gradients\n",
    "    loss.backward() # Compute new gradients\n",
    "    optimizer.step() # Apply these gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5 PyTorch CUDA 接口\n",
    "\n",
    "PyTorch 的优势之一是为张量和 autograd 库提供 CUDA 接口。使用 CUDA GPU，你不仅可以加速神经网络训练和推断，还可以加速任何映射至 PyTorch 张量的工作负载。\n",
    "\n",
    "你可以调用 torch.cuda.is_available() 函数，检查 PyTorch 中是否有可用 CUDA。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great, you have a GPU\n"
     ]
    }
   ],
   "source": [
    "cuda_gpu = torch.cuda.is_available()\n",
    "if (cuda_gpu):\n",
    "    print(\"Great, you have a GPU\")\n",
    "else:\n",
    "    print(\"Life is shor -- consider a GPU!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "很好，现在你有 GPU 了。\n",
    "\n",
    ".cuda()\n",
    "\n",
    "之后，使用 cuda 加速代码就和调用一样简单。如果你在张量上调用 .cuda()，则它将执行从 CPU 到 CUDA GPU 的数据迁移。如果你在模型上调用 .cuda()，则它不仅将所有内部储存移到 GPU，还将整个计算图映射至 GPU。\n",
    "\n",
    "要想将张量或模型复制回 CPU，比如想和 NumPy 交互，你可以调用 .cpu()。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "if cuda_gpu:\n",
    "    x = x.cuda()\n",
    "    print(type(x.data))\n",
    "    \n",
    "x = x.cpu()\n",
    "print(type(x.data))\n",
    "\n",
    "#我们来定义两个函数（训练函数和测试函数）来使用我们的模型执行训练和推断任务。\n",
    "#该代码同样来自 PyTorch 官方教程，我们摘选了所有训练／推断的必要步骤。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于训练和测试网络，我们需要执行一系列动作，这些动作可直接映射至 PyTorch 代码：\n",
    "\n",
    "1. 我们将模型转换到训练／推断模式；\n",
    "\n",
    "2. 我们通过在数据集上成批获取图像，以迭代训练模型；\n",
    "\n",
    "3. 对于每一个批量的图像，我们都要加载数据和标注，运行网络的前向步骤来获取模型输出；\n",
    "\n",
    "4. 我们定义损失函数，计算每一个批量的模型输出和目标之间的损失；\n",
    "\n",
    "5. 训练时，我们初始化梯度为零，使用上一步定义的优化器和反向传播，来计算所有与损失有关的层级梯度；\n",
    "\n",
    "6. 训练时，我们执行权重更新步骤。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, criterion, optimizer, data_loader):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        if cuda_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            model.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        output = model(data)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (batch_idx+1) % 400 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, (batch_idx+1) * len(data), len(data_loader.dataset),\n",
    "                100. * (batch_idx+1) / len(data_loader), loss.data[0]))\n",
    "\n",
    "\n",
    "def test(model, epoch, criterion, data_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in data_loader:\n",
    "        if cuda_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            model.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += criterion(output, target).data[0]\n",
    "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "\n",
    "    test_loss /= len(data_loader) # loss function already averages over batch size\n",
    "    acc = correct / len(data_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(data_loader.dataset), 100. * acc))\n",
    "    return (acc, test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 使用 PyTorch 进行数据分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 torch.nn 库构建模型\n",
    "\n",
    "使用 torch.autograd 库训练模型\n",
    "\n",
    "将数据封装进 torch.utils.data.Dataset 库\n",
    "\n",
    "使用 NumPy interface 连接你的模型、数据和你最喜欢的工具\n",
    "\n",
    "在查看复杂模型之前，我们先来看个简单的：简单合成数据集上的线性回归，我们可以使用 sklearn 工具生成这样的合成数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set()\n",
    "\n",
    "x_train, y_train, W_target = make_regression(n_samples=100, n_features=1, noise=10, coef=True)\n",
    "\n",
    "df = pd.DataFrame(data={'X':x_train.ravel(), 'Y':y_train.ravel()})\n",
    "\n",
    "sns.lmplot(x='X', y='Y', data=df, fit_reg=True)\n",
    "plt.show()\n",
    "\n",
    "x_torch = torch.FloatTensor(x_train)\n",
    "y_torch = torch.FloatTensor(y_train)\n",
    "y_torch = y_torch.view(y_torch.size()[0],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch 的 nn 库中有大量有用的模块，其中一个就是线性模块。如名字所示，它对输入执行线性变换，即线性回归。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_size, output_size)\n",
    "        \n",
    "    def forward(slef, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "model = LinearRegression(1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要训练线性回归，我们需要从 nn 库中添加合适的损失函数。对于线性回归，我们将使用 MSELoss()——均方差损失函数。\n",
    "\n",
    "我们还需要使用优化函数（SGD），并运行与之前示例类似的反向传播。本质上，我们重复上文定义的 train() 函数中的步骤。不能直接使用该函数的原因是我们实现它的目的是分类而不是回归，以及我们使用交叉熵损失和最大元素的索引作为模型预测。而对于线性回归，我们使用线性层的输出作为预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-c4d7f6d9663e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_torch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_torch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-399039f9f502>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(slef, x)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslef\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(50):\n",
    "    data, target = Variable(x_torch), Variable(y_torch)\n",
    "    output = model(data)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "predicted = model(Variable(x_torch)).data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们可以打印出原始数据和适合 PyTorch 的线性回归。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_train, y_train, 'o', label='Original data')\n",
    "plt.plot(x_train, predicted, label='Fitted line')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了转向更复杂的模型，我们下载了 MNIST 数据集至「datasets」文件夹中，并测试一些 PyTorch 中可用的初始预处理。PyTorch 具备数据加载器和处理器，可用于不同的数据集。数据集下载好后，你可以随时使用。你还可以将数据包装进 PyTorch 张量，创建自己的数据加载器类别。\n",
    "\n",
    "批大小（batch size）是机器学习中的术语，指一次迭代中使用的训练样本数量。批大小可以是以下三种之一：\n",
    "\n",
    "batch 模式：批大小等于整个数据集，因此迭代和 epoch 值一致；\n",
    "\n",
    "mini-batch 模式：批大小大于 1 但小于整个数据集的大小。通常，数量可以是能被整个数据集整除的值。\n",
    "\n",
    "随机模式：批大小等于 1。因此梯度和神经网络参数在每个样本之后都要更新。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "batch_num_size = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True, transform=transforms.Compose(\n",
    "                                                                [transforms.ToTensor(),\n",
    "                                                                 transforms.Normalize((0.1307,),(0.38081,))\n",
    "                                                                ])),\n",
    "                                                                batch_size=batch_num_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data',train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])), \n",
    "    batch_size=batch_num_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. PyTorch 中的 LeNet 卷积神经网络（CNN）\n",
    "\n",
    "现在我们从头开始创建第一个简单神经网络。该网络要执行图像分类，识别 MNIST 数据集中的手写数字。这是一个四层的卷积神经网络（CNN），一种分析 MNIST 数据集的常见架构。该代码来自 PyTorch 官方教程，你可以在这里（http://pytorch.org/tutorials/）找到更多示例。\n",
    "\n",
    "我们将使用 torch.nn 库中的多个模块：\n",
    "\n",
    "1. 线性层：使用层的权重对输入张量执行线性变换；\n",
    "\n",
    "2. Conv1 和 Conv2：卷积层，每个层输出在卷积核（小尺寸的权重张量）和同样尺寸输入区域之间的点积；\n",
    "\n",
    "3. Relu：修正线性单元函数，使用逐元素的激活函数 max(0,x)；\n",
    "\n",
    "4. 池化层：使用 max 运算执行特定区域的下采样（通常 2x2 像素）；\n",
    "\n",
    "5. Dropout2D：随机将输入张量的所有通道设为零。当特征图具备强相关时，dropout2D 提升特征图之间的独立性；\n",
    "\n",
    "6. Softmax：将 Log(Softmax(x)) 函数应用到 n 维输入张量，以使输出在 0 到 1 之间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,10,kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10,20,kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320,50)\n",
    "        self.fc2 = nn.Linear(50,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x),2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)),2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建 LeNet 类后，创建对象并移至 GPU："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet()\n",
    "if cuda_gpu:\n",
    "    model.cuda()\n",
    "\n",
    "print ('MNIST_net model:\\n')\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要训练该模型，我们需要使用带动量的 SGD，学习率为 0.01，momentum 为 0.5。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctierion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.005, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "仅仅需要 5 个 epoch（一个 epoch 意味着你使用整个训练数据集来更新训练模型的权重），我们就可以训练出一个相当准确的 LeNet 模型。这段代码检查可以确定文件中是否已有预训练好的模型。有则加载；无则训练一个并保存至磁盘。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "epochs = 5\n",
    "if (os.path.isfile('pretrained/MNIST_net.t7')):\n",
    "    print('Loading model')\n",
    "    model.load_state_dict(torch.load('pretrained/MNIST_net.t7', map_location=lambda storage, loc: stroage))\n",
    "    acc, loss = test(model, 1, criterion, test_loader)\n",
    "else:\n",
    "    print('Training model')\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(model, epoch, criterion, optimizer, train_loader)\n",
    "        acc, loss = test(model, 1, criterion, test_loader)\n",
    "    torch.save(model.state_dict(), 'pretrained/MNIST_net.t7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Internal models:')\n",
    "for idx, m in enumerate(model.named_modules()):\n",
    "    print(idx, '->', m)\n",
    "    print ('-------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你可以使用 .cpu() 方法将张量移至 CPU（或确保它在那里）。或者，当 GPU 可用时（torch.cuda. 可用），使用 .cuda() 方法将张量移至 GPU。你可以看到张量是否在 GPU 上，其类型为 torch.cuda.FloatTensor。如果张量在 CPU 上，则其类型为 torch.FloatTensor。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(t.cpu().data))\n",
    "if torch.cuda.is_avaiable():\n",
    "    print(\"Cuda is available\")\n",
    "    print(type(t.cuda().data))\n",
    "else:\n",
    "    ptint(\"Cuda is NOT available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果张量在 CPU 上，我们可以将其转换成 NumPy 数组，其共享同样的内存位置，改变其中一个就会改变另一个。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-0.3912791   0.24573803  0.45478058 -0.45120567  0.39158708]\n",
      "   [-0.13757849  0.12105626  0.36446506  0.39877683  0.49306166]\n",
      "   [-0.01521182 -0.04394877 -0.38341808 -0.33683634 -0.27335304]]\n",
      "\n",
      "  [[-0.3963651  -0.00416881 -0.06545174 -0.03920037  0.06572026]\n",
      "   [ 0.09094918  0.35999125  0.07388479 -0.28238183 -0.4808771 ]\n",
      "   [ 0.25956297  0.14970964  0.00621635 -0.15522039  0.41722834]]\n",
      "\n",
      "  [[ 0.46329546  0.48456812  0.12774795  0.18951124  0.10282016]\n",
      "   [-0.12238079  0.28188038 -0.19418973  0.27752513  0.06172985]\n",
      "   [-0.12351465 -0.13244814  0.36165935  0.17103124  0.1247015 ]]\n",
      "\n",
      "  [[ 0.49548292 -0.2146399  -0.41214764  0.40083027 -0.36242276]\n",
      "   [-0.1590749  -0.32912892 -0.01102668  0.08458453  0.18740821]\n",
      "   [-0.46156746 -0.44796753 -0.1252867   0.09546596  0.1588915 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.22083509 -0.08572704 -0.21920216  0.0342406   0.12859708]\n",
      "   [-0.0972212   0.1681754  -0.33815652 -0.12030417  0.45011836]\n",
      "   [ 0.38609642  0.04301894 -0.33611935 -0.11923742 -0.03642416]]\n",
      "\n",
      "  [[-0.37368816 -0.32521623  0.2585023   0.02581698 -0.00486749]\n",
      "   [ 0.4081207  -0.45556676 -0.17122573 -0.4452237  -0.3816144 ]\n",
      "   [ 0.32999963 -0.25463766 -0.33307117  0.01759183  0.33684522]]\n",
      "\n",
      "  [[ 0.49088925 -0.42296076  0.39105463  0.19867045 -0.46018028]\n",
      "   [ 0.02043313  0.1998182  -0.00353593  0.20092309 -0.38752174]\n",
      "   [-0.2463631   0.2475245   0.41385168  0.4927625   0.04231614]]\n",
      "\n",
      "  [[-0.22885269  0.2908342   0.16065854 -0.1267854   0.06054449]\n",
      "   [ 0.49507236 -0.3449272   0.4088238   0.47757286 -0.06085688]\n",
      "   [ 0.07863462  0.10628468  0.44710445  0.12513036  0.19788736]]]]\n",
      "<class 'numpy.ndarray'>\n",
      "(2, 4, 3, 5)\n",
      "[[[[-0.3912791   0.24573803  0.45478058 -0.45120567  0.39158708]\n",
      "   [-0.13757849  0.12105626  0.36446506  0.39877683  0.49306166]\n",
      "   [-0.01521182 -0.04394877 -0.38341808 -0.33683634 -0.27335304]]\n",
      "\n",
      "  [[-0.3963651  -0.00416881 -0.06545174 -0.03920037  0.06572026]\n",
      "   [ 0.09094918  0.35999125  0.07388479 -0.28238183 -0.4808771 ]\n",
      "   [ 0.25956297  0.14970964  0.00621635 -0.15522039  0.41722834]]\n",
      "\n",
      "  [[ 0.46329546  0.48456812  0.12774795  0.18951124  0.10282016]\n",
      "   [-0.12238079  0.28188038 -0.19418973  0.27752513  0.06172985]\n",
      "   [-0.12351465 -0.13244814  0.36165935  0.17103124  0.1247015 ]]\n",
      "\n",
      "  [[ 0.49548292 -0.2146399  -0.41214764  0.40083027 -0.36242276]\n",
      "   [-0.1590749  -0.32912892 -0.01102668  0.08458453  0.18740821]\n",
      "   [-0.46156746 -0.44796753 -0.1252867   0.09546596  0.1588915 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.22083509 -0.08572704 -0.21920216  0.0342406   0.12859708]\n",
      "   [-0.0972212   0.1681754  -0.33815652 -0.12030417  0.45011836]\n",
      "   [ 0.38609642  0.04301894 -0.33611935 -0.11923742 -0.03642416]]\n",
      "\n",
      "  [[-0.37368816 -0.32521623  0.2585023   0.02581698 -0.00486749]\n",
      "   [ 0.4081207  -0.45556676 -0.17122573 -0.4452237  -0.3816144 ]\n",
      "   [ 0.32999963 -0.25463766 -0.33307117  0.01759183  0.33684522]]\n",
      "\n",
      "  [[ 0.49088925 -0.42296076  0.39105463  0.19867045 -0.46018028]\n",
      "   [ 0.02043313  0.1998182  -0.00353593  0.20092309 -0.38752174]\n",
      "   [-0.2463631   0.2475245   0.41385168  0.4927625   0.04231614]]\n",
      "\n",
      "  [[-0.22885269  0.2908342   0.16065854 -0.1267854   0.06054449]\n",
      "   [ 0.49507236 -0.3449272   0.4088238   0.47757286 -0.06085688]\n",
      "   [ 0.07863462  0.10628468  0.44710445  0.12513036  0.19788736]]]]\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    try:\n",
    "        print(t.data.numpy())\n",
    "    except RuntimeError as e:\n",
    "        \"you can't transform a GPU tensor to a numpy nd array, you have to copy your weight tender to cpu and then get the numpy array\"\n",
    "    \n",
    "print(type(t.cpu().data.numpy()))\n",
    "print(t.cpu().data.numpy().shape)\n",
    "print(t.cpu().data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
