{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference: https://zhuanlan.zhihu.com/p/101799677"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0469e-38, 9.3674e-39, 9.9184e-39],\n",
      "        [8.7245e-39, 9.2755e-39, 8.9082e-39],\n",
      "        [9.9184e-39, 8.4490e-39, 9.6429e-39],\n",
      "        [1.0653e-38, 1.0469e-38, 4.2246e-39],\n",
      "        [1.0378e-38, 9.6429e-39, 9.2755e-39]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3568, 0.1898, 0.9638],\n",
      "        [0.8893, 0.9131, 0.9649],\n",
      "        [0.1871, 0.2894, 0.4746],\n",
      "        [0.3597, 0.4167, 0.0734],\n",
      "        [0.6067, 0.8453, 0.1729]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = x.new_ones(5, 3, dtype=torch.double)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6485,  0.3901, -1.5344],\n",
      "        [-0.1758, -2.4787, -0.0823],\n",
      "        [ 1.1017,  0.2345, -0.4665],\n",
      "        [ 1.0825, -1.8110,  0.7313],\n",
      "        [ 1.1274,  1.0616,  0.7046]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn_like(x, dtype=torch.float)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 獲取size\n",
    "print(x.size())\n",
    "torch.Size([5,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5735,  1.1917, -0.7651],\n",
      "        [ 0.8087, -2.3707,  0.0809],\n",
      "        [ 1.3146,  0.5293,  0.3896],\n",
      "        [ 1.6812, -1.2449,  1.6115],\n",
      "        [ 1.3525,  1.2751,  1.6569]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5,3)\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5735,  1.1917, -0.7651],\n",
      "        [ 0.8087, -2.3707,  0.0809],\n",
      "        [ 1.3146,  0.5293,  0.3896],\n",
      "        [ 1.6812, -1.2449,  1.6115],\n",
      "        [ 1.3525,  1.2751,  1.6569]])\n"
     ]
    }
   ],
   "source": [
    "# 加法2\n",
    "print(torch.add(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5735,  1.1917, -0.7651],\n",
      "        [ 0.8087, -2.3707,  0.0809],\n",
      "        [ 1.3146,  0.5293,  0.3896],\n",
      "        [ 1.6812, -1.2449,  1.6115],\n",
      "        [ 1.3525,  1.2751,  1.6569]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5,3)\n",
    "torch.add(x, y, out = result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5735,  1.1917, -0.7651],\n",
      "        [ 0.8087, -2.3707,  0.0809],\n",
      "        [ 1.3146,  0.5293,  0.3896],\n",
      "        [ 1.6812, -1.2449,  1.6115],\n",
      "        [ 1.3525,  1.2751,  1.6569]])\n"
     ]
    }
   ],
   "source": [
    "# 替換, adds x to y\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3901, -2.4787,  0.2345, -1.8110,  1.0616])\n"
     ]
    }
   ],
   "source": [
    "print(x[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "# torch.view与Numpy的reshape类似\n",
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8) # size -1 從其他維度推斷\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.7742])\n",
      "1.7742080688476562\n"
     ]
    }
   ],
   "source": [
    "# 如果你有只有一个元素的张量，使用.item()来得到Python数据类型的数值\n",
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将Torch Tensor转换成NumPy array，反之亦然，这是轻而易举的。 Torch Tensor和NumPy array将共享它们的底层内存位置，更改其中一个将更改另一个。 将Torch Tensor转换为NumPy array。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# see how the numpy array changed in value\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy Array 转化成 Torch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 使用from_numpy自動轉化\n",
    "import numpy as np\n",
    "a = np.ones(7)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有的 Tensor 类型默认都是基于CPU， CharTensor 类型不支持到 NumPy 的转换."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.7742], device='cuda:0')\n",
      "tensor([2.7742], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# CUDA 张量. 使用.to 方法 可以将Tensor移动到任何设备中\n",
    "\n",
    "# is_available 函數判斷是否有cuda可以使用\n",
    "# ``torch.device`` 將張量移動到指定的設備中\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") # a CUDA 設備對象\n",
    "    y = torch.ones_like(x, device=device) # 直接從GPU創建張量 \n",
    "    x = x.to(device) #或者直接使用``.to(\"cuda\")``將張量移動到CUDA中\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to('cpu', torch.double))  # ``.TO``也會對變量的類型做更改"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自动求导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x000001656E957EC8>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "None\n",
      "True\n",
      "<SumBackward0 object at 0x000001656E9F3808>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 2)\n",
    "a = ((a*3)/(a-1))\n",
    "print(a.requires_grad)\n",
    "print(a.grad_fn)\n",
    "\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "b = (a*a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1390.2953, -179.9784,  978.3918], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "    \n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"
     ]
    }
   ],
   "source": [
    "gradients = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
    "y.backward(gradients)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "print((x**2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x**2).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-58-8be51be2434d>, line 39)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-58-8be51be2434d>\"\u001b[1;36m, line \u001b[1;32m39\u001b[0m\n\u001b[1;33m    (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "Net(\n",
    "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
    "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
    "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
    "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
    "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用cifar10训练一个分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, \n",
    "                                        download=True, transform= transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, \n",
    "                                          shuffle=True, num_workers=2)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                          download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                            shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 展示圖像的函數\n",
    "def imshow(img):\n",
    "    img = img/2 + 0.5  #unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    \n",
    "# 獲取隨機數據\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# 展示圖象\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# 顯示圖像標簽\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))\n",
    "# Predicted:  plane plane plane plane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "refernce: https://www.jiqizhixin.com/articles/2018-04-11-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch 是一个建立在 Torch 库之上的 Python 包，旨在加速深度学习应用。\n",
    "\n",
    "PyTorch 提供一种类似 NumPy 的抽象方法来表征张量（或多维数组），它可以利用 GPU 来加速训练。\n",
    "\n",
    "**1.1 PyTorch 张量**\n",
    "\n",
    "PyTorch 的关键数据结构是张量，即多维数组。其功能与 NumPy 的 ndarray 对象类似，如下我们可以使用 torch.Tensor() 创建张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a 2-D pytorch tensor (i.e., a matrix)\n",
    "import torch\n",
    "pytorch_tensor = torch.Tensor(10, 20)\n",
    "print(\"type: \", type(pytorch_tensor), \" and size: \", pytorch_tensor.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你需要一个兼容 NumPy 的表征，或者你想从现有的 NumPy 对象中创建一个 PyTorch 张量，那么就很简单了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the pytorch tensor to a numpy array:\n",
    "numpy_tensor = pytorch_tensor.numpy()\n",
    "print(\"type:\", type(numpy_tensor), \" and size\", numpy_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the numpy array to a Pytorch Tensor:\n",
    "print(\"type:\", type(numpy_tensor), \" and size\", torch.Tensor(numpy_tensor).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 PyTorch vs. NumPy\n",
    "\n",
    "PyTorch 并不是 NumPy 的简单替代品，但它实现了很多 NumPy 功能。其中有一个不便之处是其命名规则，有时候它和 NumPy 的命名方法相当不同。我们来举几个例子说明其中的区别："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 張量創建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "t = torch.rand(2,4,3,5)\n",
    "a = np.random.rand(2,4,3,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 張量分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.rand(2,4,3,5)\n",
    "a = t.numpy()\n",
    "pytorch_slice = t[0, 1:3, :, 4]\n",
    "numpy_slice = a[0, 1:3, :, 4]\n",
    "print('Tensor[0, 1:3, :, 4]:\\n', pytorch_slice)\n",
    "print('NdArray[0, 1:3, :, 4]:\\n]', numpy_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 張量 Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t - 0.5\n",
    "a = t.numpy()\n",
    "pytorch_masked = t[t > 0]\n",
    "numpy_masked = a[a > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_masked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 張量重塑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_reshape = t.view([6, 5, 4])\n",
    "numpy_reshape = a.reshape([6, 5, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_reshape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_reshape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Pytorch變量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch張量的簡單封裝<br>\n",
    "幫組建立計算圖<br>\n",
    "AUTOGRAD(自動微分庫)的必要部分<br>\n",
    "將關於這些變量的梯度保存在.grad中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/pytorch001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算图和变量：在 PyTorch 中，神经网络会使用相互连接的变量作为计算图来表示。PyTorch 允许通过代码构建计算图来构建网络模型；之后 PyTorch 会简化估计模型权重的流程，例如通过自动计算梯度的方式。\n",
    "\n",
    "举例来说，假设我们想构建两层模型，那么首先要为输入和输出创建张量变量。我们可以将 PyTorch Tensor 包装进 Variable 对象中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "x = Variable(torch.randn(4, 1), requires_grad=False)\n",
    "y = Variable(torch.randn(3, 1), requires_grad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们把 requires_grad 设置为 True，表明我们想要自动计算梯度，这将用于反向传播中以优化权重。\n",
    "\n",
    "现在我们来定义权重："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = Variable(torch.randn(5, 4), requires_grad=True)\n",
    "w2 = Variable(torch.randn(3, 5), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6239,  0.7876, -1.3007,  1.3560],\n",
      "        [ 0.0798, -1.0963, -0.2139, -1.2197],\n",
      "        [ 1.2730, -0.6968, -0.7353,  0.1223],\n",
      "        [-0.6757,  0.0997,  0.7450, -0.0569],\n",
      "        [ 1.0749, -0.0421, -1.5753,  1.9511]], requires_grad=True) \n",
      "\n",
      "torch.Size([5, 4]) \n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 訓練模型\n",
    "def model_forward(x):\n",
    "    return F.sigmoid(w2@F.sigmoid(w1@x))\n",
    "\n",
    "print(w1, '\\n')\n",
    "print(w1.data.shape,'\\n')\n",
    "print(w1.grad)  # Ubutuakktm non-existent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 PyTorch 反向传播\n",
    "\n",
    "这样我们有了输入和目标、模型权重，那么是时候训练模型了。我们需要三个组件：\n",
    "\n",
    "损失函数：描述我们模型的预测距离目标还有多远；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "优化算法：用于更新权重；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.SGD([w1, w2], lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "反向传播步骤："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Norto\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    loss = criterion(model_forward(x), y)\n",
    "    optimizer.zero_grad() # Zero-out previous gradients\n",
    "    loss.backward() # Compute new gradients\n",
    "    optimizer.step() # Apply these gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5 PyTorch CUDA 接口\n",
    "\n",
    "PyTorch 的优势之一是为张量和 autograd 库提供 CUDA 接口。使用 CUDA GPU，你不仅可以加速神经网络训练和推断，还可以加速任何映射至 PyTorch 张量的工作负载。\n",
    "\n",
    "你可以调用 torch.cuda.is_available() 函数，检查 PyTorch 中是否有可用 CUDA。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great, you have a GPU\n"
     ]
    }
   ],
   "source": [
    "cuda_gpu = torch.cuda.is_available()\n",
    "if (cuda_gpu):\n",
    "    print(\"Great, you have a GPU\")\n",
    "else:\n",
    "    print(\"Life is shor -- consider a GPU!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "很好，现在你有 GPU 了。\n",
    "\n",
    ".cuda()\n",
    "\n",
    "之后，使用 cuda 加速代码就和调用一样简单。如果你在张量上调用 .cuda()，则它将执行从 CPU 到 CUDA GPU 的数据迁移。如果你在模型上调用 .cuda()，则它不仅将所有内部储存移到 GPU，还将整个计算图映射至 GPU。\n",
    "\n",
    "要想将张量或模型复制回 CPU，比如想和 NumPy 交互，你可以调用 .cpu()。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "if cuda_gpu:\n",
    "    x = x.cuda()\n",
    "    print(type(x.data))\n",
    "    \n",
    "x = x.cpu()\n",
    "print(type(x.data))\n",
    "\n",
    "#我们来定义两个函数（训练函数和测试函数）来使用我们的模型执行训练和推断任务。\n",
    "#该代码同样来自 PyTorch 官方教程，我们摘选了所有训练／推断的必要步骤。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于训练和测试网络，我们需要执行一系列动作，这些动作可直接映射至 PyTorch 代码：\n",
    "\n",
    "1. 我们将模型转换到训练／推断模式；\n",
    "\n",
    "2. 我们通过在数据集上成批获取图像，以迭代训练模型；\n",
    "\n",
    "3. 对于每一个批量的图像，我们都要加载数据和标注，运行网络的前向步骤来获取模型输出；\n",
    "\n",
    "4. 我们定义损失函数，计算每一个批量的模型输出和目标之间的损失；\n",
    "\n",
    "5. 训练时，我们初始化梯度为零，使用上一步定义的优化器和反向传播，来计算所有与损失有关的层级梯度；\n",
    "\n",
    "6. 训练时，我们执行权重更新步骤。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, criterion, optimizer, data_loader):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        if cuda_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            model.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        output = model(data)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (batch_idx+1) % 400 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, (batch_idx+1) * len(data), len(data_loader.dataset),\n",
    "                100. * (batch_idx+1) / len(data_loader), loss.data[0]))\n",
    "\n",
    "\n",
    "def test(model, epoch, criterion, data_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in data_loader:\n",
    "        if cuda_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            model.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += criterion(output, target).data[0]\n",
    "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "\n",
    "    test_loss /= len(data_loader) # loss function already averages over batch size\n",
    "    acc = correct / len(data_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(data_loader.dataset), 100. * acc))\n",
    "    return (acc, test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 使用 PyTorch 进行数据分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 torch.nn 库构建模型\n",
    "\n",
    "使用 torch.autograd 库训练模型\n",
    "\n",
    "将数据封装进 torch.utils.data.Dataset 库\n",
    "\n",
    "使用 NumPy interface 连接你的模型、数据和你最喜欢的工具\n",
    "\n",
    "在查看复杂模型之前，我们先来看个简单的：简单合成数据集上的线性回归，我们可以使用 sklearn 工具生成这样的合成数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set()\n",
    "\n",
    "x_train, y_train, W_target = make_regression(n_samples=100, n_features=1, noise=10, coef=True)\n",
    "\n",
    "df = pd.DataFrame(data={'X':x_train.ravel(), 'Y':y_train.ravel()})\n",
    "\n",
    "sns.lmplot(x='X', y='Y', data=df, fit_reg=True)\n",
    "plt.show()\n",
    "\n",
    "x_torch = torch.FloatTensor(x_train)\n",
    "y_torch = torch.FloatTensor(y_train)\n",
    "y_torch = y_torch.view(y_torch.size()[0],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch 的 nn 库中有大量有用的模块，其中一个就是线性模块。如名字所示，它对输入执行线性变换，即线性回归。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_size, output_size)\n",
    "        \n",
    "    def forward(slef, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "model = LinearRegression(1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要训练线性回归，我们需要从 nn 库中添加合适的损失函数。对于线性回归，我们将使用 MSELoss()——均方差损失函数。\n",
    "\n",
    "我们还需要使用优化函数（SGD），并运行与之前示例类似的反向传播。本质上，我们重复上文定义的 train() 函数中的步骤。不能直接使用该函数的原因是我们实现它的目的是分类而不是回归，以及我们使用交叉熵损失和最大元素的索引作为模型预测。而对于线性回归，我们使用线性层的输出作为预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Variable' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c4d7f6d9663e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_torch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_torch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Variable' is not defined"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(50):\n",
    "    data, target = Variable(x_torch), Variable(y_torch)\n",
    "    output = model(data)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "predicted = model(Variable(x_torch)).data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们可以打印出原始数据和适合 PyTorch 的线性回归。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_train, y_train, 'o', label='Original data')\n",
    "plt.plot(x_train, predicted, label='Fitted line')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了转向更复杂的模型，我们下载了 MNIST 数据集至「datasets」文件夹中，并测试一些 PyTorch 中可用的初始预处理。PyTorch 具备数据加载器和处理器，可用于不同的数据集。数据集下载好后，你可以随时使用。你还可以将数据包装进 PyTorch 张量，创建自己的数据加载器类别。\n",
    "\n",
    "批大小（batch size）是机器学习中的术语，指一次迭代中使用的训练样本数量。批大小可以是以下三种之一：\n",
    "\n",
    "batch 模式：批大小等于整个数据集，因此迭代和 epoch 值一致；\n",
    "\n",
    "mini-batch 模式：批大小大于 1 但小于整个数据集的大小。通常，数量可以是能被整个数据集整除的值。\n",
    "\n",
    "随机模式：批大小等于 1。因此梯度和神经网络参数在每个样本之后都要更新。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "batch_num_size = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True, transform=transforms.Compose(\n",
    "                                                                [transforms.ToTensor(),\n",
    "                                                                 transforms.Normalize((0.1307,),(0.38081,))\n",
    "                                                                ])),\n",
    "                                                                batch_size=batch_num_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data',train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])), \n",
    "    batch_size=batch_num_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. PyTorch 中的 LeNet 卷积神经网络（CNN）\n",
    "\n",
    "现在我们从头开始创建第一个简单神经网络。该网络要执行图像分类，识别 MNIST 数据集中的手写数字。这是一个四层的卷积神经网络（CNN），一种分析 MNIST 数据集的常见架构。该代码来自 PyTorch 官方教程，你可以在这里（http://pytorch.org/tutorials/）找到更多示例。\n",
    "\n",
    "我们将使用 torch.nn 库中的多个模块：\n",
    "\n",
    "1. 线性层：使用层的权重对输入张量执行线性变换；\n",
    "\n",
    "2. Conv1 和 Conv2：卷积层，每个层输出在卷积核（小尺寸的权重张量）和同样尺寸输入区域之间的点积；\n",
    "\n",
    "3. Relu：修正线性单元函数，使用逐元素的激活函数 max(0,x)；\n",
    "\n",
    "4. 池化层：使用 max 运算执行特定区域的下采样（通常 2x2 像素）；\n",
    "\n",
    "5. Dropout2D：随机将输入张量的所有通道设为零。当特征图具备强相关时，dropout2D 提升特征图之间的独立性；\n",
    "\n",
    "6. Softmax：将 Log(Softmax(x)) 函数应用到 n 维输入张量，以使输出在 0 到 1 之间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,10,kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10,20,kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320,50)\n",
    "        self.fc2 = nn.Linear(50,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x),2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)),2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建 LeNet 类后，创建对象并移至 GPU："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet()\n",
    "if cuda_gpu:\n",
    "    model.cuda()\n",
    "\n",
    "print ('MNIST_net model:\\n')\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要训练该模型，我们需要使用带动量的 SGD，学习率为 0.01，momentum 为 0.5。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctierion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.005, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "仅仅需要 5 个 epoch（一个 epoch 意味着你使用整个训练数据集来更新训练模型的权重），我们就可以训练出一个相当准确的 LeNet 模型。这段代码检查可以确定文件中是否已有预训练好的模型。有则加载；无则训练一个并保存至磁盘。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "epochs = 5\n",
    "if (os.path.isfile('pretrained/MNIST_net.t7')):\n",
    "    print('Loading model')\n",
    "    model.load_state_dict(torch.load('pretrained/MNIST_net.t7', map_location=lambda storage, loc: stroage))\n",
    "    acc, loss = test(model, 1, criterion, test_loader)\n",
    "else:\n",
    "    print('Training model')\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(model, epoch, criterion, optimizer, train_loader)\n",
    "        acc, loss = test(model, 1, criterion, test_loader)\n",
    "    torch.save(model.state_dict(), 'pretrained/MNIST_net.t7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
