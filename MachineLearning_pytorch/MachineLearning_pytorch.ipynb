{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference: https://zhuanlan.zhihu.com/p/101799677"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0469e-38, 9.3674e-39, 9.9184e-39],\n",
      "        [8.7245e-39, 9.2755e-39, 8.9082e-39],\n",
      "        [9.9184e-39, 8.4490e-39, 9.6429e-39],\n",
      "        [1.0653e-38, 1.0469e-38, 4.2246e-39],\n",
      "        [1.0378e-38, 9.6429e-39, 9.2755e-39]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3568, 0.1898, 0.9638],\n",
      "        [0.8893, 0.9131, 0.9649],\n",
      "        [0.1871, 0.2894, 0.4746],\n",
      "        [0.3597, 0.4167, 0.0734],\n",
      "        [0.6067, 0.8453, 0.1729]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = x.new_ones(5, 3, dtype=torch.double)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6485,  0.3901, -1.5344],\n",
      "        [-0.1758, -2.4787, -0.0823],\n",
      "        [ 1.1017,  0.2345, -0.4665],\n",
      "        [ 1.0825, -1.8110,  0.7313],\n",
      "        [ 1.1274,  1.0616,  0.7046]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn_like(x, dtype=torch.float)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 獲取size\n",
    "print(x.size())\n",
    "torch.Size([5,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5735,  1.1917, -0.7651],\n",
      "        [ 0.8087, -2.3707,  0.0809],\n",
      "        [ 1.3146,  0.5293,  0.3896],\n",
      "        [ 1.6812, -1.2449,  1.6115],\n",
      "        [ 1.3525,  1.2751,  1.6569]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5,3)\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5735,  1.1917, -0.7651],\n",
      "        [ 0.8087, -2.3707,  0.0809],\n",
      "        [ 1.3146,  0.5293,  0.3896],\n",
      "        [ 1.6812, -1.2449,  1.6115],\n",
      "        [ 1.3525,  1.2751,  1.6569]])\n"
     ]
    }
   ],
   "source": [
    "# 加法2\n",
    "print(torch.add(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5735,  1.1917, -0.7651],\n",
      "        [ 0.8087, -2.3707,  0.0809],\n",
      "        [ 1.3146,  0.5293,  0.3896],\n",
      "        [ 1.6812, -1.2449,  1.6115],\n",
      "        [ 1.3525,  1.2751,  1.6569]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5,3)\n",
    "torch.add(x, y, out = result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5735,  1.1917, -0.7651],\n",
      "        [ 0.8087, -2.3707,  0.0809],\n",
      "        [ 1.3146,  0.5293,  0.3896],\n",
      "        [ 1.6812, -1.2449,  1.6115],\n",
      "        [ 1.3525,  1.2751,  1.6569]])\n"
     ]
    }
   ],
   "source": [
    "# 替換, adds x to y\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3901, -2.4787,  0.2345, -1.8110,  1.0616])\n"
     ]
    }
   ],
   "source": [
    "print(x[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "# torch.view与Numpy的reshape类似\n",
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8) # size -1 從其他維度推斷\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.7742])\n",
      "1.7742080688476562\n"
     ]
    }
   ],
   "source": [
    "# 如果你有只有一个元素的张量，使用.item()来得到Python数据类型的数值\n",
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将Torch Tensor转换成NumPy array，反之亦然，这是轻而易举的。 Torch Tensor和NumPy array将共享它们的底层内存位置，更改其中一个将更改另一个。 将Torch Tensor转换为NumPy array。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# see how the numpy array changed in value\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy Array 转化成 Torch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 使用from_numpy自動轉化\n",
    "import numpy as np\n",
    "a = np.ones(7)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有的 Tensor 类型默认都是基于CPU， CharTensor 类型不支持到 NumPy 的转换."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.7742], device='cuda:0')\n",
      "tensor([2.7742], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# CUDA 张量. 使用.to 方法 可以将Tensor移动到任何设备中\n",
    "\n",
    "# is_available 函數判斷是否有cuda可以使用\n",
    "# ``torch.device`` 將張量移動到指定的設備中\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") # a CUDA 設備對象\n",
    "    y = torch.ones_like(x, device=device) # 直接從GPU創建張量 \n",
    "    x = x.to(device) #或者直接使用``.to(\"cuda\")``將張量移動到CUDA中\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to('cpu', torch.double))  # ``.TO``也會對變量的類型做更改"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自动求导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x000001656E957EC8>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "None\n",
      "True\n",
      "<SumBackward0 object at 0x000001656E9F3808>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 2)\n",
    "a = ((a*3)/(a-1))\n",
    "print(a.requires_grad)\n",
    "print(a.grad_fn)\n",
    "\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "b = (a*a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1390.2953, -179.9784,  978.3918], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "    \n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"
     ]
    }
   ],
   "source": [
    "gradients = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
    "y.backward(gradients)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "print((x**2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x**2).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-58-8be51be2434d>, line 39)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-58-8be51be2434d>\"\u001b[1;36m, line \u001b[1;32m39\u001b[0m\n\u001b[1;33m    (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "Net(\n",
    "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
    "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
    "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
    "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
    "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用cifar10训练一个分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, \n",
    "                                        download=True, transform= transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, \n",
    "                                          shuffle=True, num_workers=2)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                          download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                            shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 展示圖像的函數\n",
    "def imshow(img):\n",
    "    img = img/2 + 0.5  #unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    \n",
    "# 獲取隨機數據\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# 展示圖象\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# 顯示圖像標簽\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))\n",
    "# Predicted:  plane plane plane plane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "refernce: https://www.jiqizhixin.com/articles/2018-04-11-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch 是一个建立在 Torch 库之上的 Python 包，旨在加速深度学习应用。\n",
    "\n",
    "PyTorch 提供一种类似 NumPy 的抽象方法来表征张量（或多维数组），它可以利用 GPU 来加速训练。\n",
    "\n",
    "**1.1 PyTorch 张量**\n",
    "\n",
    "PyTorch 的关键数据结构是张量，即多维数组。其功能与 NumPy 的 ndarray 对象类似，如下我们可以使用 torch.Tensor() 创建张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a 2-D pytorch tensor (i.e., a matrix)\n",
    "import torch\n",
    "pytorch_tensor = torch.Tensor(10, 20)\n",
    "print(\"type: \", type(pytorch_tensor), \" and size: \", pytorch_tensor.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你需要一个兼容 NumPy 的表征，或者你想从现有的 NumPy 对象中创建一个 PyTorch 张量，那么就很简单了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the pytorch tensor to a numpy array:\n",
    "numpy_tensor = pytorch_tensor.numpy()\n",
    "print(\"type:\", type(numpy_tensor), \" and size\", numpy_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the numpy array to a Pytorch Tensor:\n",
    "print(\"type:\", type(numpy_tensor), \" and size\", torch.Tensor(numpy_tensor).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 PyTorch vs. NumPy\n",
    "\n",
    "PyTorch 并不是 NumPy 的简单替代品，但它实现了很多 NumPy 功能。其中有一个不便之处是其命名规则，有时候它和 NumPy 的命名方法相当不同。我们来举几个例子说明其中的区别："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 張量創建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "t = torch.rand(2,4,3,5)\n",
    "a = np.random.rand(2,4,3,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 張量分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.rand(2,4,3,5)\n",
    "a = t.numpy()\n",
    "pytorch_slice = t[0, 1:3, :, 4]\n",
    "numpy_slice = a[0, 1:3, :, 4]\n",
    "print('Tensor[0, 1:3, :, 4]:\\n', pytorch_slice)\n",
    "print('NdArray[0, 1:3, :, 4]:\\n]', numpy_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 張量 Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t - 0.5\n",
    "a = t.numpy()\n",
    "pytorch_masked = t[t > 0]\n",
    "numpy_masked = a[a > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_masked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 張量重塑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_reshape = t.view([6, 5, 4])\n",
    "numpy_reshape = a.reshape([6, 5, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_reshape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_reshape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Pytorch變量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch張量的簡單封裝<br>\n",
    "幫組建立計算圖<br>\n",
    "AUTOGRAD(自動微分庫)的必要部分<br>\n",
    "將關於這些變量的梯度保存在.grad中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/pytorch001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算图和变量：在 PyTorch 中，神经网络会使用相互连接的变量作为计算图来表示。PyTorch 允许通过代码构建计算图来构建网络模型；之后 PyTorch 会简化估计模型权重的流程，例如通过自动计算梯度的方式。\n",
    "\n",
    "举例来说，假设我们想构建两层模型，那么首先要为输入和输出创建张量变量。我们可以将 PyTorch Tensor 包装进 Variable 对象中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "x = Variable(torch.randn(4, 1), requires_grad=False)\n",
    "y = Variable(torch.randn(3, 1), requires_grad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们把 requires_grad 设置为 True，表明我们想要自动计算梯度，这将用于反向传播中以优化权重。\n",
    "\n",
    "现在我们来定义权重："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = Variable(torch.randn(5, 4), requires_grad=True)\n",
    "w2 = Variable(torch.randn(3, 5), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7006, -1.2087, -1.4938,  0.5381],\n",
      "        [-0.8231, -1.4751,  1.0087, -1.0076],\n",
      "        [-0.2677, -1.8074, -0.6393,  0.0632],\n",
      "        [ 0.5488, -1.8783,  1.0975,  0.5336],\n",
      "        [ 0.9841,  1.1684, -1.3276, -0.4068]], requires_grad=True) \n",
      "\n",
      "torch.Size([5, 4]) \n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 訓練模型\n",
    "def model_forward(x):\n",
    "    return F.sigmoid(w2@F.sigmoid(w1@x))\n",
    "\n",
    "print(w1, '\\n')\n",
    "print(w1.data.shape,'\\n')\n",
    "print(w1.grad)  # Ubutuakktm non-existent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 PyTorch 反向传播\n",
    "\n",
    "这样我们有了输入和目标、模型权重，那么是时候训练模型了。我们需要三个组件：\n",
    "\n",
    "损失函数：描述我们模型的预测距离目标还有多远；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "优化算法：用于更新权重；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.SGD([w1, w2], lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "反向传播步骤："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Norto\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    loss = criterion(model_forward(x), y)\n",
    "    optimizer.zero_grad() # Zero-out previous gradients\n",
    "    loss.backward() # Compute new gradients\n",
    "    optimizer.step() # Apply these gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5 PyTorch CUDA 接口\n",
    "\n",
    "PyTorch 的优势之一是为张量和 autograd 库提供 CUDA 接口。使用 CUDA GPU，你不仅可以加速神经网络训练和推断，还可以加速任何映射至 PyTorch 张量的工作负载。\n",
    "\n",
    "你可以调用 torch.cuda.is_available() 函数，检查 PyTorch 中是否有可用 CUDA。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great, you have a GPU\n"
     ]
    }
   ],
   "source": [
    "cuda_gpu = torch.cuda.is_available()\n",
    "if (cuda_gpu):\n",
    "    print(\"Great, you have a GPU\")\n",
    "else:\n",
    "    print(\"Life is shor -- consider a GPU!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "很好，现在你有 GPU 了。\n",
    "\n",
    ".cuda()\n",
    "\n",
    "之后，使用 cuda 加速代码就和调用一样简单。如果你在张量上调用 .cuda()，则它将执行从 CPU 到 CUDA GPU 的数据迁移。如果你在模型上调用 .cuda()，则它不仅将所有内部储存移到 GPU，还将整个计算图映射至 GPU。\n",
    "\n",
    "要想将张量或模型复制回 CPU，比如想和 NumPy 交互，你可以调用 .cpu()。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "if cuda_gpu:\n",
    "    x = x.cuda()\n",
    "    print(type(x.data))\n",
    "    \n",
    "x = x.cpu()\n",
    "print(type(x.data))\n",
    "\n",
    "#我们来定义两个函数（训练函数和测试函数）来使用我们的模型执行训练和推断任务。\n",
    "#该代码同样来自 PyTorch 官方教程，我们摘选了所有训练／推断的必要步骤。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于训练和测试网络，我们需要执行一系列动作，这些动作可直接映射至 PyTorch 代码：\n",
    "\n",
    "1. 我们将模型转换到训练／推断模式；\n",
    "\n",
    "2. 我们通过在数据集上成批获取图像，以迭代训练模型；\n",
    "\n",
    "3. 对于每一个批量的图像，我们都要加载数据和标注，运行网络的前向步骤来获取模型输出；\n",
    "\n",
    "4. 我们定义损失函数，计算每一个批量的模型输出和目标之间的损失；\n",
    "\n",
    "5. 训练时，我们初始化梯度为零，使用上一步定义的优化器和反向传播，来计算所有与损失有关的层级梯度；\n",
    "\n",
    "6. 训练时，我们执行权重更新步骤。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, criterion, optimizer, data_loader):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        if cuda_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            model.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        output = model(data)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (batch_idx+1) % 400 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, (batch_idx+1) * len(data), len(data_loader.dataset),\n",
    "                100. * (batch_idx+1) / len(data_loader), loss.data[0]))\n",
    "\n",
    "\n",
    "def test(model, epoch, criterion, data_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in data_loader:\n",
    "        if cuda_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            model.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += criterion(output, target).data[0]\n",
    "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "\n",
    "    test_loss /= len(data_loader) # loss function already averages over batch size\n",
    "    acc = correct / len(data_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(data_loader.dataset), 100. * acc))\n",
    "    return (acc, test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 使用 PyTorch 进行数据分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 torch.nn 库构建模型\n",
    "\n",
    "使用 torch.autograd 库训练模型\n",
    "\n",
    "将数据封装进 torch.utils.data.Dataset 库\n",
    "\n",
    "使用 NumPy interface 连接你的模型、数据和你最喜欢的工具\n",
    "\n",
    "在查看复杂模型之前，我们先来看个简单的：简单合成数据集上的线性回归，我们可以使用 sklearn 工具生成这样的合成数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set()\n",
    "\n",
    "x_train, y_train, W_target = make_regression(n_samples=100, n_features=1, noise=10, coef=True)\n",
    "\n",
    "df = pd.DataFrame(data={'X':x_train.ravel(), 'Y':y_train.ravel()})\n",
    "\n",
    "sns.lmplot(x='X', y='Y', data=df, fit_reg=True)\n",
    "plt.show()\n",
    "\n",
    "x_torch = torch.FloatTensor(x_train)\n",
    "y_torch = torch.FloatTensor(y_train)\n",
    "y_torch = y_torch.view(y_torch.size()[0],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch 的 nn 库中有大量有用的模块，其中一个就是线性模块。如名字所示，它对输入执行线性变换，即线性回归。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_size, output_size)\n",
    "        \n",
    "    def forward(slef, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "model = LinearRegression(1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要训练线性回归，我们需要从 nn 库中添加合适的损失函数。对于线性回归，我们将使用 MSELoss()——均方差损失函数。\n",
    "\n",
    "我们还需要使用优化函数（SGD），并运行与之前示例类似的反向传播。本质上，我们重复上文定义的 train() 函数中的步骤。不能直接使用该函数的原因是我们实现它的目的是分类而不是回归，以及我们使用交叉熵损失和最大元素的索引作为模型预测。而对于线性回归，我们使用线性层的输出作为预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-c4d7f6d9663e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_torch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_torch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-399039f9f502>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(slef, x)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslef\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(50):\n",
    "    data, target = Variable(x_torch), Variable(y_torch)\n",
    "    output = model(data)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "predicted = model(Variable(x_torch)).data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们可以打印出原始数据和适合 PyTorch 的线性回归。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-c7350e39a2b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'o'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Original data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Fitted line'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predicted' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_train, y_train, 'o', label='Original data')\n",
    "plt.plot(x_train, predicted, label='Fitted line')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了转向更复杂的模型，我们下载了 MNIST 数据集至「datasets」文件夹中，并测试一些 PyTorch 中可用的初始预处理。PyTorch 具备数据加载器和处理器，可用于不同的数据集。数据集下载好后，你可以随时使用。你还可以将数据包装进 PyTorch 张量，创建自己的数据加载器类别。\n",
    "\n",
    "批大小（batch size）是机器学习中的术语，指一次迭代中使用的训练样本数量。批大小可以是以下三种之一：\n",
    "\n",
    "batch 模式：批大小等于整个数据集，因此迭代和 epoch 值一致；\n",
    "\n",
    "mini-batch 模式：批大小大于 1 但小于整个数据集的大小。通常，数量可以是能被整个数据集整除的值。\n",
    "\n",
    "随机模式：批大小等于 1。因此梯度和神经网络参数在每个样本之后都要更新。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "batch_num_size = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True, transform=transforms.Compose(\n",
    "                                                                [transforms.ToTensor(),\n",
    "                                                                 transforms.Normalize((0.1307,),(0.38081,))\n",
    "                                                                ])),\n",
    "                                                                batch_size=batch_num_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data',train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])), \n",
    "    batch_size=batch_num_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. PyTorch 中的 LeNet 卷积神经网络（CNN）\n",
    "\n",
    "现在我们从头开始创建第一个简单神经网络。该网络要执行图像分类，识别 MNIST 数据集中的手写数字。这是一个四层的卷积神经网络（CNN），一种分析 MNIST 数据集的常见架构。该代码来自 PyTorch 官方教程，你可以在这里（http://pytorch.org/tutorials/）找到更多示例。\n",
    "\n",
    "我们将使用 torch.nn 库中的多个模块：\n",
    "\n",
    "1. 线性层：使用层的权重对输入张量执行线性变换；\n",
    "\n",
    "2. Conv1 和 Conv2：卷积层，每个层输出在卷积核（小尺寸的权重张量）和同样尺寸输入区域之间的点积；\n",
    "\n",
    "3. Relu：修正线性单元函数，使用逐元素的激活函数 max(0,x)；\n",
    "\n",
    "4. 池化层：使用 max 运算执行特定区域的下采样（通常 2x2 像素）；\n",
    "\n",
    "5. Dropout2D：随机将输入张量的所有通道设为零。当特征图具备强相关时，dropout2D 提升特征图之间的独立性；\n",
    "\n",
    "6. Softmax：将 Log(Softmax(x)) 函数应用到 n 维输入张量，以使输出在 0 到 1 之间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,10,kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10,20,kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320,50)\n",
    "        self.fc2 = nn.Linear(50,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x),2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)),2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建 LeNet 类后，创建对象并移至 GPU："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST_net model:\n",
      "\n",
      "LeNet(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = LeNet()\n",
    "if cuda_gpu:\n",
    "    model.cuda()\n",
    "\n",
    "print ('MNIST_net model:\\n')\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要训练该模型，我们需要使用带动量的 SGD，学习率为 0.01，momentum 为 0.5。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctierion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.005, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "仅仅需要 5 个 epoch（一个 epoch 意味着你使用整个训练数据集来更新训练模型的权重），我们就可以训练出一个相当准确的 LeNet 模型。这段代码检查可以确定文件中是否已有预训练好的模型。有则加载；无则训练一个并保存至磁盘。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "epochs = 5\n",
    "if (os.path.isfile('pretrained/MNIST_net.t7')):\n",
    "    print('Loading model')\n",
    "    model.load_state_dict(torch.load('pretrained/MNIST_net.t7', map_location=lambda storage, loc: stroage))\n",
    "    acc, loss = test(model, 1, criterion, test_loader)\n",
    "else:\n",
    "    print('Training model')\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(model, epoch, criterion, optimizer, train_loader)\n",
    "        acc, loss = test(model, 1, criterion, test_loader)\n",
    "    torch.save(model.state_dict(), 'pretrained/MNIST_net.t7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal models:\n",
      "0 -> ('', LeNet(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "))\n",
      "-------------------------------------------------------------------------\n",
      "1 -> ('conv1', Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1)))\n",
      "-------------------------------------------------------------------------\n",
      "2 -> ('conv2', Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1)))\n",
      "-------------------------------------------------------------------------\n",
      "3 -> ('conv2_drop', Dropout2d(p=0.5, inplace=False))\n",
      "-------------------------------------------------------------------------\n",
      "4 -> ('fc1', Linear(in_features=320, out_features=50, bias=True))\n",
      "-------------------------------------------------------------------------\n",
      "5 -> ('fc2', Linear(in_features=50, out_features=10, bias=True))\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print ('Internal models:')\n",
    "for idx, m in enumerate(model.named_modules()):\n",
    "    print(idx, '->', m)\n",
    "    print ('-------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
