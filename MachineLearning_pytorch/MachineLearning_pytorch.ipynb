{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference: https://zhuanlan.zhihu.com/p/101799677"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.9830e+18,  5.4651e-43, -3.9830e+18],\n",
      "        [ 5.4651e-43, -3.9828e+18,  5.4651e-43],\n",
      "        [-3.9828e+18,  5.4651e-43, -3.9826e+18],\n",
      "        [ 5.4651e-43, -3.9826e+18,  5.4651e-43],\n",
      "        [-3.9826e+18,  5.4651e-43, -3.9826e+18]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6604, 0.7379, 0.1192],\n",
      "        [0.8583, 0.0164, 0.2356],\n",
      "        [0.7433, 0.1963, 0.9755],\n",
      "        [0.8687, 0.3586, 0.6321],\n",
      "        [0.1501, 0.7177, 0.6657]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = x.new_ones(5, 3, dtype=torch.double)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4872, -0.0134,  0.8560],\n",
      "        [-0.4319,  1.9692,  0.6007],\n",
      "        [-1.3057,  0.1212,  1.5204],\n",
      "        [ 1.1853, -0.8292,  0.1865],\n",
      "        [ 0.8168, -0.5766,  1.1799]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn_like(x, dtype=torch.float)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 獲取size\n",
    "print(x.size())\n",
    "torch.Size([5,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4979,  0.6362,  0.9685],\n",
      "        [-0.1553,  2.4654,  1.2631],\n",
      "        [-0.6036,  0.9839,  2.3661],\n",
      "        [ 1.4032, -0.3995,  0.7656],\n",
      "        [ 1.5628,  0.3429,  1.1966]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5,3)\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4979,  0.6362,  0.9685],\n",
      "        [-0.1553,  2.4654,  1.2631],\n",
      "        [-0.6036,  0.9839,  2.3661],\n",
      "        [ 1.4032, -0.3995,  0.7656],\n",
      "        [ 1.5628,  0.3429,  1.1966]])\n"
     ]
    }
   ],
   "source": [
    "# 加法2\n",
    "print(torch.add(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4979,  0.6362,  0.9685],\n",
      "        [-0.1553,  2.4654,  1.2631],\n",
      "        [-0.6036,  0.9839,  2.3661],\n",
      "        [ 1.4032, -0.3995,  0.7656],\n",
      "        [ 1.5628,  0.3429,  1.1966]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5,3)\n",
    "torch.add(x, y, out = result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4979,  0.6362,  0.9685],\n",
      "        [-0.1553,  2.4654,  1.2631],\n",
      "        [-0.6036,  0.9839,  2.3661],\n",
      "        [ 1.4032, -0.3995,  0.7656],\n",
      "        [ 1.5628,  0.3429,  1.1966]])\n"
     ]
    }
   ],
   "source": [
    "# 替換, adds x to y\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0134,  1.9692,  0.1212, -0.8292, -0.5766])\n"
     ]
    }
   ],
   "source": [
    "print(x[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "# torch.view与Numpy的reshape类似\n",
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8) # size -1 從其他維度推斷\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9878])\n",
      "0.9878203272819519\n"
     ]
    }
   ],
   "source": [
    "# 如果你有只有一个元素的张量，使用.item()来得到Python数据类型的数值\n",
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将Torch Tensor转换成NumPy array，反之亦然，这是轻而易举的。 Torch Tensor和NumPy array将共享它们的底层内存位置，更改其中一个将更改另一个。 将Torch Tensor转换为NumPy array。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# see how the numpy array changed in value\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy Array 转化成 Torch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 使用from_numpy自動轉化\n",
    "import numpy as np\n",
    "a = np.ones(7)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有的 Tensor 类型默认都是基于CPU， CharTensor 类型不支持到 NumPy 的转换."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.9878], device='cuda:0')\n",
      "tensor([1.9878], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# CUDA 张量. 使用.to 方法 可以将Tensor移动到任何设备中\n",
    "\n",
    "# is_available 函數判斷是否有cuda可以使用\n",
    "# ``torch.device`` 將張量移動到指定的設備中\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") # a CUDA 設備對象\n",
    "    y = torch.ones_like(x, device=device) # 直接從GPU創建張量 \n",
    "    x = x.to(device) #或者直接使用``.to(\"cuda\")``將張量移動到CUDA中\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to('cpu', torch.double))  # ``.TO``也會對變量的類型做更改"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自动求导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x00000186A62C2308>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "None\n",
      "True\n",
      "<SumBackward0 object at 0x00000186A62CEE48>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 2)\n",
    "a = ((a*3)/(a-1))\n",
    "print(a.requires_grad)\n",
    "print(a.grad_fn)\n",
    "\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "b = (a*a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -136.4454, -1110.6400,   915.3831], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "    \n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0480e+02, 2.0480e+03, 2.0480e-01])\n"
     ]
    }
   ],
   "source": [
    "gradients = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
    "y.backward(gradients)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "print((x**2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x**2).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "Net(\n",
    "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
    "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
    "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
    "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
    "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用cifar10训练一个分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, \n",
    "                                        download=True, transform= transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, \n",
    "                                          shuffle=True, num_workers=2)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                          download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                            shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " deer plane   cat   cat\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 展示圖像的函數\n",
    "def imshow(img):\n",
    "    img = img/2 + 0.5  #unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    \n",
    "# 獲取隨機數據\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# 展示圖象\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# 顯示圖像標簽\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))\n",
    "# Predicted:  plane plane plane plane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "refernce: https://www.jiqizhixin.com/articles/2018-04-11-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch 是一个建立在 Torch 库之上的 Python 包，旨在加速深度学习应用。\n",
    "\n",
    "PyTorch 提供一种类似 NumPy 的抽象方法来表征张量（或多维数组），它可以利用 GPU 来加速训练。\n",
    "\n",
    "**1.1 PyTorch 张量**\n",
    "\n",
    "PyTorch 的关键数据结构是张量，即多维数组。其功能与 NumPy 的 ndarray 对象类似，如下我们可以使用 torch.Tensor() 创建张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type:  <class 'torch.Tensor'>  and size:  torch.Size([10, 20])\n"
     ]
    }
   ],
   "source": [
    "# Generate a 2-D pytorch tensor (i.e., a matrix)\n",
    "import torch\n",
    "pytorch_tensor = torch.Tensor(10, 20)\n",
    "print(\"type: \", type(pytorch_tensor), \" and size: \", pytorch_tensor.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你需要一个兼容 NumPy 的表征，或者你想从现有的 NumPy 对象中创建一个 PyTorch 张量，那么就很简单了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'numpy.ndarray'>  and size (10, 20)\n"
     ]
    }
   ],
   "source": [
    "# Convert the pytorch tensor to a numpy array:\n",
    "numpy_tensor = pytorch_tensor.numpy()\n",
    "print(\"type:\", type(numpy_tensor), \" and size\", numpy_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'numpy.ndarray'>  and size torch.Size([10, 20])\n"
     ]
    }
   ],
   "source": [
    "# Convert the numpy array to a Pytorch Tensor:\n",
    "print(\"type:\", type(numpy_tensor), \" and size\", torch.Tensor(numpy_tensor).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 PyTorch vs. NumPy\n",
    "\n",
    "PyTorch 并不是 NumPy 的简单替代品，但它实现了很多 NumPy 功能。其中有一个不便之处是其命名规则，有时候它和 NumPy 的命名方法相当不同。我们来举几个例子说明其中的区别："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 張量創建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "t = torch.rand(2,4,3,5)\n",
    "a = np.random.rand(2,4,3,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 張量分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor[0, 1:3, :, 4]:\n",
      " tensor([[0.4960, 0.9719, 0.2435],\n",
      "        [0.4931, 0.3807, 0.1943]])\n",
      "NdArray[0, 1:3, :, 4]:\n",
      "] [[0.4959833  0.971874   0.2434935 ]\n",
      " [0.49314225 0.38066447 0.19427013]]\n"
     ]
    }
   ],
   "source": [
    "t = torch.rand(2,4,3,5)\n",
    "a = t.numpy()\n",
    "pytorch_slice = t[0, 1:3, :, 4]\n",
    "numpy_slice = a[0, 1:3, :, 4]\n",
    "print('Tensor[0, 1:3, :, 4]:\\n', pytorch_slice)\n",
    "print('NdArray[0, 1:3, :, 4]:\\n]', numpy_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 張量 Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t - 0.5\n",
    "a = t.numpy()\n",
    "pytorch_masked = t[t > 0]\n",
    "numpy_masked = a[a > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_masked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 張量重塑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_reshape = t.view([6, 5, 4])\n",
    "numpy_reshape = a.reshape([6, 5, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3499e-01,  4.3874e-02, -3.2541e-01, -4.8674e-01],\n",
       "         [ 1.3957e-01, -1.8254e-01, -8.0059e-02,  3.9846e-01],\n",
       "         [-1.9758e-01, -3.0766e-02,  2.4679e-01,  4.5374e-01],\n",
       "         [-2.4648e-01,  3.7080e-01, -3.5233e-01, -1.8802e-01],\n",
       "         [-3.1814e-01,  2.6961e-01,  5.2826e-02, -4.0167e-03]],\n",
       "\n",
       "        [[-4.3739e-02,  1.6435e-01,  6.2586e-02,  2.6949e-01],\n",
       "         [ 4.7187e-01, -2.0288e-02, -8.4710e-02, -4.6763e-01],\n",
       "         [-3.3020e-01, -2.5651e-01,  4.6512e-01, -1.3980e-01],\n",
       "         [-4.8669e-01,  2.1759e-01, -6.8578e-03, -3.2854e-01],\n",
       "         [-4.1243e-01, -3.1477e-01,  3.6455e-01, -1.1934e-01]],\n",
       "\n",
       "        [[ 4.6741e-01,  5.0917e-02, -3.5496e-01,  2.0762e-01],\n",
       "         [-3.0573e-01,  2.1459e-01,  1.6520e-01, -8.9986e-02],\n",
       "         [-3.1704e-01,  4.2026e-01, -4.9812e-02, -3.5537e-01],\n",
       "         [-2.8585e-02,  3.5656e-01,  3.9501e-01,  4.4415e-01],\n",
       "         [-4.4905e-01,  4.5867e-01,  1.7886e-01,  3.4721e-01]],\n",
       "\n",
       "        [[ 3.5079e-01,  1.7365e-01, -1.9594e-01,  1.6284e-01],\n",
       "         [ 4.0867e-01,  2.8856e-01, -5.4024e-02,  2.6836e-01],\n",
       "         [ 4.8688e-01, -7.3949e-02,  3.1438e-01,  1.8145e-01],\n",
       "         [-1.0808e-01, -1.4264e-01,  3.6791e-01,  1.2240e-01],\n",
       "         [-3.2871e-01, -1.3193e-01, -3.2077e-01,  7.4903e-02]],\n",
       "\n",
       "        [[-4.4814e-01, -2.2836e-01, -9.7425e-02, -4.1508e-01],\n",
       "         [ 2.7563e-01,  3.0900e-01,  2.4902e-01,  4.2498e-01],\n",
       "         [-3.0351e-01,  1.0091e-02, -2.6272e-02, -1.1515e-01],\n",
       "         [ 7.8956e-02, -4.3245e-01, -2.5507e-01, -8.0394e-02],\n",
       "         [-4.3397e-01, -2.2827e-01,  4.2218e-01, -4.9403e-01]],\n",
       "\n",
       "        [[-9.5255e-02,  5.9070e-02,  2.6762e-05,  4.5575e-01],\n",
       "         [-1.5371e-01,  2.5420e-01,  1.7119e-02, -2.6463e-01],\n",
       "         [-4.0772e-01,  4.2675e-01, -1.7531e-01,  4.5995e-01],\n",
       "         [ 6.5627e-02, -2.7369e-01,  3.7112e-01, -1.9460e-01],\n",
       "         [ 4.7209e-01, -1.5691e-02, -4.3676e-01,  3.5149e-01]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_reshape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.3498873e-01,  4.3873966e-02, -3.2541257e-01, -4.8674423e-01],\n",
       "        [ 1.3957298e-01, -1.8253958e-01, -8.0059171e-02,  3.9845812e-01],\n",
       "        [-1.9758362e-01, -3.0766368e-02,  2.4678808e-01,  4.5373970e-01],\n",
       "        [-2.4648064e-01,  3.7079901e-01, -3.5232890e-01, -1.8801910e-01],\n",
       "        [-3.1814086e-01,  2.6960909e-01,  5.2825689e-02, -4.0166974e-03]],\n",
       "\n",
       "       [[-4.3738902e-02,  1.6435188e-01,  6.2585831e-02,  2.6948851e-01],\n",
       "        [ 4.7187400e-01, -2.0287752e-02, -8.4710360e-02, -4.6763009e-01],\n",
       "        [-3.3019799e-01, -2.5650650e-01,  4.6511549e-01, -1.3979840e-01],\n",
       "        [-4.8669022e-01,  2.1759480e-01, -6.8577528e-03, -3.2854253e-01],\n",
       "        [-4.1243243e-01, -3.1476820e-01,  3.6454761e-01, -1.1933553e-01]],\n",
       "\n",
       "       [[ 4.6740568e-01,  5.0916553e-02, -3.5495883e-01,  2.0762414e-01],\n",
       "        [-3.0572987e-01,  2.1458781e-01,  1.6519970e-01, -8.9986384e-02],\n",
       "        [-3.1704164e-01,  4.2026389e-01, -4.9811542e-02, -3.5537052e-01],\n",
       "        [-2.8584838e-02,  3.5655677e-01,  3.9501256e-01,  4.4414604e-01],\n",
       "        [-4.4905448e-01,  4.5867217e-01,  1.7886102e-01,  3.4720546e-01]],\n",
       "\n",
       "       [[ 3.5079038e-01,  1.7364746e-01, -1.9593841e-01,  1.6284293e-01],\n",
       "        [ 4.0867448e-01,  2.8855836e-01, -5.4023683e-02,  2.6835936e-01],\n",
       "        [ 4.8688269e-01, -7.3949158e-02,  3.1438464e-01,  1.8145275e-01],\n",
       "        [-1.0808420e-01, -1.4263648e-01,  3.6791390e-01,  1.2239611e-01],\n",
       "        [-3.2871133e-01, -1.3192892e-01, -3.2076728e-01,  7.4903131e-02]],\n",
       "\n",
       "       [[-4.4814336e-01, -2.2835809e-01, -9.7424865e-02, -4.1507888e-01],\n",
       "        [ 2.7562851e-01,  3.0899751e-01,  2.4901909e-01,  4.2498457e-01],\n",
       "        [-3.0351371e-01,  1.0090768e-02, -2.6272476e-02, -1.1514604e-01],\n",
       "        [ 7.8955889e-02, -4.3244505e-01, -2.5506872e-01, -8.0393553e-02],\n",
       "        [-4.3397230e-01, -2.2826934e-01,  4.2218077e-01, -4.9402857e-01]],\n",
       "\n",
       "       [[-9.5255315e-02,  5.9070468e-02,  2.6762486e-05,  4.5575207e-01],\n",
       "        [-1.5371007e-01,  2.5419849e-01,  1.7119110e-02, -2.6463360e-01],\n",
       "        [-4.0771955e-01,  4.2675489e-01, -1.7531300e-01,  4.5995474e-01],\n",
       "        [ 6.5627337e-02, -2.7368993e-01,  3.7112063e-01, -1.9460171e-01],\n",
       "        [ 4.7208881e-01, -1.5690923e-02, -4.3675816e-01,  3.5148871e-01]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_reshape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Pytorch變量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch張量的簡單封裝<br>\n",
    "幫組建立計算圖<br>\n",
    "AUTOGRAD(自動微分庫)的必要部分<br>\n",
    "將關於這些變量的梯度保存在.grad中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/pytorch001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算图和变量：在 PyTorch 中，神经网络会使用相互连接的变量作为计算图来表示。PyTorch 允许通过代码构建计算图来构建网络模型；之后 PyTorch 会简化估计模型权重的流程，例如通过自动计算梯度的方式。\n",
    "\n",
    "举例来说，假设我们想构建两层模型，那么首先要为输入和输出创建张量变量。我们可以将 PyTorch Tensor 包装进 Variable 对象中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "x = Variable(torch.randn(4, 1), requires_grad=False)\n",
    "y = Variable(torch.randn(3, 1), requires_grad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们把 requires_grad 设置为 True，表明我们想要自动计算梯度，这将用于反向传播中以优化权重。\n",
    "\n",
    "现在我们来定义权重："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = Variable(torch.randn(5, 4), requires_grad=True)\n",
    "w2 = Variable(torch.randn(3, 5), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5874,  0.4285,  1.3146, -1.5830],\n",
      "        [ 1.6895,  0.6176,  0.7884,  2.4284],\n",
      "        [ 1.0964,  1.3882,  0.6652,  0.5075],\n",
      "        [-2.2959,  1.9077, -0.4946, -1.1653],\n",
      "        [ 0.5242,  1.0479, -1.9800, -1.0730]], requires_grad=True) \n",
      "\n",
      "torch.Size([5, 4]) \n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 訓練模型\n",
    "def model_forward(x):\n",
    "    return F.sigmoid(w2@F.sigmoid(w1@x))\n",
    "\n",
    "print(w1, '\\n')\n",
    "print(w1.data.shape,'\\n')\n",
    "print(w1.grad)  # Ubutuakktm non-existent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 PyTorch 反向传播\n",
    "\n",
    "这样我们有了输入和目标、模型权重，那么是时候训练模型了。我们需要三个组件：\n",
    "\n",
    "损失函数：描述我们模型的预测距离目标还有多远；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "优化算法：用于更新权重；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.SGD([w1, w2], lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "反向传播步骤："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Norto\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    loss = criterion(model_forward(x), y)\n",
    "    optimizer.zero_grad() # Zero-out previous gradients\n",
    "    loss.backward() # Compute new gradients\n",
    "    optimizer.step() # Apply these gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5 PyTorch CUDA 接口\n",
    "\n",
    "PyTorch 的优势之一是为张量和 autograd 库提供 CUDA 接口。使用 CUDA GPU，你不仅可以加速神经网络训练和推断，还可以加速任何映射至 PyTorch 张量的工作负载。\n",
    "\n",
    "你可以调用 torch.cuda.is_available() 函数，检查 PyTorch 中是否有可用 CUDA。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great, you have a GPU\n"
     ]
    }
   ],
   "source": [
    "cuda_gpu = torch.cuda.is_available()\n",
    "if (cuda_gpu):\n",
    "    print(\"Great, you have a GPU\")\n",
    "else:\n",
    "    print(\"Life is shor -- consider a GPU!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "很好，现在你有 GPU 了。\n",
    "\n",
    ".cuda()\n",
    "\n",
    "之后，使用 cuda 加速代码就和调用一样简单。如果你在张量上调用 .cuda()，则它将执行从 CPU 到 CUDA GPU 的数据迁移。如果你在模型上调用 .cuda()，则它不仅将所有内部储存移到 GPU，还将整个计算图映射至 GPU。\n",
    "\n",
    "要想将张量或模型复制回 CPU，比如想和 NumPy 交互，你可以调用 .cpu()。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "if cuda_gpu:\n",
    "    x = x.cuda()\n",
    "    print(type(x.data))\n",
    "    \n",
    "x = x.cpu()\n",
    "print(type(x.data))\n",
    "\n",
    "#我们来定义两个函数（训练函数和测试函数）来使用我们的模型执行训练和推断任务。\n",
    "#该代码同样来自 PyTorch 官方教程，我们摘选了所有训练／推断的必要步骤。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于训练和测试网络，我们需要执行一系列动作，这些动作可直接映射至 PyTorch 代码：\n",
    "\n",
    "1. 我们将模型转换到训练／推断模式；\n",
    "\n",
    "2. 我们通过在数据集上成批获取图像，以迭代训练模型；\n",
    "\n",
    "3. 对于每一个批量的图像，我们都要加载数据和标注，运行网络的前向步骤来获取模型输出；\n",
    "\n",
    "4. 我们定义损失函数，计算每一个批量的模型输出和目标之间的损失；\n",
    "\n",
    "5. 训练时，我们初始化梯度为零，使用上一步定义的优化器和反向传播，来计算所有与损失有关的层级梯度；\n",
    "\n",
    "6. 训练时，我们执行权重更新步骤。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, criterion, optimizer, data_loader):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        if cuda_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            model.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        output = model(data)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (batch_idx+1) % 400 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, (batch_idx+1) * len(data), len(data_loader.dataset),\n",
    "                100. * (batch_idx+1) / len(data_loader), loss.data[0]))\n",
    "\n",
    "\n",
    "def test(model, epoch, criterion, data_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in data_loader:\n",
    "        if cuda_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            model.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += criterion(output, target).data[0]\n",
    "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "\n",
    "    test_loss /= len(data_loader) # loss function already averages over batch size\n",
    "    acc = correct / len(data_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(data_loader.dataset), 100. * acc))\n",
    "    return (acc, test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 使用 PyTorch 进行数据分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 torch.nn 库构建模型\n",
    "\n",
    "使用 torch.autograd 库训练模型\n",
    "\n",
    "将数据封装进 torch.utils.data.Dataset 库\n",
    "\n",
    "使用 NumPy interface 连接你的模型、数据和你最喜欢的工具\n",
    "\n",
    "在查看复杂模型之前，我们先来看个简单的：简单合成数据集上的线性回归，我们可以使用 sklearn 工具生成这样的合成数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "\n",
    "x_train, y_train, W_target = make_regression(n_samples=100, n_features=1, noise=10, coef=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
